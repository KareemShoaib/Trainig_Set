{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breast_Cancer_NB_KMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('breast_cancer_diagnosis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Diagnosis Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['diagnosiss'] = label_encoder.fit_transform(df['diagnosis'])\n",
    "df.drop(columns=['diagnosis'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing all the numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kokor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_array_api.py:472: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "c:\\Users\\kokor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_array_api.py:489: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "null_data = df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing Null Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Data:\n",
      "id                           0\n",
      "radius_mean                  0\n",
      "texture_mean                 0\n",
      "perimeter_mean               0\n",
      "area_mean                    0\n",
      "smoothness_mean              0\n",
      "compactness_mean             0\n",
      "concavity_mean               0\n",
      "concave points_mean          0\n",
      "symmetry_mean                0\n",
      "fractal_dimension_mean       0\n",
      "radius_se                    0\n",
      "texture_se                   0\n",
      "perimeter_se                 0\n",
      "area_se                      0\n",
      "smoothness_se                0\n",
      "compactness_se               0\n",
      "concavity_se                 0\n",
      "concave points_se            0\n",
      "symmetry_se                  0\n",
      "fractal_dimension_se         0\n",
      "radius_worst                 0\n",
      "texture_worst                0\n",
      "perimeter_worst              0\n",
      "area_worst                   0\n",
      "smoothness_worst             0\n",
      "compactness_worst            0\n",
      "concavity_worst              0\n",
      "concave points_worst         0\n",
      "symmetry_worst               0\n",
      "fractal_dimension_worst      0\n",
      "Unnamed: 32                569\n",
      "diagnosiss                   0\n",
      "dtype: int64\n",
      "         id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0  0.000915     0.521037      0.022658        0.545989   0.363733   \n",
      "1  0.000915     0.643144      0.272574        0.615783   0.501591   \n",
      "2  0.092495     0.601496      0.390260        0.595743   0.449417   \n",
      "3  0.092547     0.210090      0.360839        0.233501   0.102906   \n",
      "4  0.092559     0.629893      0.156578        0.630986   0.489290   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0         0.593753          0.792037        0.703140             0.731113   \n",
      "1         0.289880          0.181768        0.203608             0.348757   \n",
      "2         0.514309          0.431017        0.462512             0.635686   \n",
      "3         0.811321          0.811361        0.565604             0.522863   \n",
      "4         0.430351          0.347893        0.463918             0.518390   \n",
      "\n",
      "   symmetry_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
      "0       0.686364  ...       0.141525         0.668310    0.450698   \n",
      "1       0.379798  ...       0.303571         0.539818    0.435214   \n",
      "2       0.509596  ...       0.360075         0.508442    0.374508   \n",
      "3       0.776263  ...       0.385928         0.241347    0.094008   \n",
      "4       0.378283  ...       0.123934         0.506948    0.341575   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0          0.601136           0.619292         0.568610              0.912027   \n",
      "1          0.347553           0.154563         0.192971              0.639175   \n",
      "2          0.483590           0.385375         0.359744              0.835052   \n",
      "3          0.915472           0.814012         0.548642              0.884880   \n",
      "4          0.437364           0.172415         0.319489              0.558419   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  diagnosiss  \n",
      "0        0.598462                 0.418864           1  \n",
      "1        0.233590                 0.222878           1  \n",
      "2        0.403706                 0.213433           1  \n",
      "3        1.000000                 0.773711           1  \n",
      "4        0.157500                 0.142595           1  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Null Data:\")\n",
    "print(null_data)\n",
    "df_modified = df.drop(columns=['Unnamed: 32'])\n",
    "print(df_modified.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the data for training & splitting the data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (X, y): (398, 31) (398,)\n",
      "Validation set shape (X, y): (171, 31) (171,)\n"
     ]
    }
   ],
   "source": [
    "X = df_modified.drop(columns=['diagnosiss'])  \n",
    "y = df_modified['diagnosiss']  \n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Verify the shapes of the subsets\n",
    "print(\"Training set shape (X, y):\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape (X, y):\", X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.001 \n",
    "no_of_neighbors=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data and Printing validation accuracy for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch's for Naive Bayes\n",
      "Epoch 1/20 - Validation Accuracy: 0.9357\n",
      "Epoch 2/20 - Validation Accuracy: 0.9357\n",
      "Epoch 3/20 - Validation Accuracy: 0.9357\n",
      "Epoch 4/20 - Validation Accuracy: 0.9357\n",
      "Epoch 5/20 - Validation Accuracy: 0.9357\n",
      "Epoch 6/20 - Validation Accuracy: 0.9357\n",
      "Epoch 7/20 - Validation Accuracy: 0.9357\n",
      "Epoch 8/20 - Validation Accuracy: 0.9357\n",
      "Epoch 9/20 - Validation Accuracy: 0.9357\n",
      "Epoch 10/20 - Validation Accuracy: 0.9357\n",
      "Epoch 11/20 - Validation Accuracy: 0.9357\n",
      "Epoch 12/20 - Validation Accuracy: 0.9357\n",
      "Epoch 13/20 - Validation Accuracy: 0.9357\n",
      "Epoch 14/20 - Validation Accuracy: 0.9357\n",
      "Epoch 15/20 - Validation Accuracy: 0.9357\n",
      "Epoch 16/20 - Validation Accuracy: 0.9357\n",
      "Epoch 17/20 - Validation Accuracy: 0.9357\n",
      "Epoch 18/20 - Validation Accuracy: 0.9357\n",
      "Epoch 19/20 - Validation Accuracy: 0.9357\n",
      "Epoch 20/20 - Validation Accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "print(\"Epoch's for Naive Bayes\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle the training data (optional)\n",
    "    shuffled_indices = np.random.permutation(len(X_train))\n",
    "    X_train_shuffled = X_train.iloc[shuffled_indices]\n",
    "    y_train_shuffled = y_train.iloc[shuffled_indices]\n",
    "    \n",
    "    # Mini-batch training\n",
    "    for batch_start in range(0, len(X_train), batch_size):\n",
    "        batch_end = batch_start + batch_size\n",
    "        X_batch = X_train_shuffled.iloc[batch_start:batch_end]\n",
    "        y_batch = y_train_shuffled.iloc[batch_start:batch_end]\n",
    "        \n",
    "        # Fit the model on the current mini-batch\n",
    "        nb_model.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
    "        \n",
    "    # Evaluate the model on the validation set\n",
    "    y_valid_pred = nb_model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data and Printing validation accuracy for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs for KNN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Validation Accuracy: 0.9649\n",
      "Epoch 2/20 - Validation Accuracy: 0.9649\n",
      "Epoch 3/20 - Validation Accuracy: 0.9649\n",
      "Epoch 4/20 - Validation Accuracy: 0.9649\n",
      "Epoch 5/20 - Validation Accuracy: 0.9649\n",
      "Epoch 6/20 - Validation Accuracy: 0.9649\n",
      "Epoch 7/20 - Validation Accuracy: 0.9649\n",
      "Epoch 8/20 - Validation Accuracy: 0.9649\n",
      "Epoch 9/20 - Validation Accuracy: 0.9649\n",
      "Epoch 10/20 - Validation Accuracy: 0.9649\n",
      "Epoch 11/20 - Validation Accuracy: 0.9649\n",
      "Epoch 12/20 - Validation Accuracy: 0.9649\n",
      "Epoch 13/20 - Validation Accuracy: 0.9649\n",
      "Epoch 14/20 - Validation Accuracy: 0.9649\n",
      "Epoch 15/20 - Validation Accuracy: 0.9649\n",
      "Epoch 16/20 - Validation Accuracy: 0.9649\n",
      "Epoch 17/20 - Validation Accuracy: 0.9649\n",
      "Epoch 18/20 - Validation Accuracy: 0.9649\n",
      "Epoch 19/20 - Validation Accuracy: 0.9649\n",
      "Epoch 20/20 - Validation Accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=no_of_neighbors)\n",
    "print (\"Epochs for KNN\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle the training data (optional)\n",
    "    shuffled_indices = np.random.permutation(len(X_train))\n",
    "    X_train_shuffled = X_train.iloc[shuffled_indices]\n",
    "    y_train_shuffled = y_train.iloc[shuffled_indices]\n",
    "    \n",
    "    # Fit the model on the entire training data\n",
    "    knn_model.fit(X_train_shuffled, y_train_shuffled)\n",
    "        \n",
    "    # Evaluate the model on the validation set\n",
    "    y_valid_pred = knn_model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV and Standard deviation of NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for GaussianNB: [0.93333333 0.96666667 0.93333333 0.93333333 1.        ]\n",
      "Mean CV score of GausianNB: 0.9533333333333334\n",
      "Standard deviation of CV scores of GaussianNB: 0.02666666666666666\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "cv_scores = cross_val_score(nb_model, X, y, cv=5)  \n",
    "print(\"Cross-validation scores for GaussianNB:\", cv_scores)\n",
    "print(\"Mean CV score of GausianNB:\", cv_scores.mean())\n",
    "print(\"Standard deviation of CV scores of GaussianNB:\", cv_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV and Standard deviation of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for KNN: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Mean CV score for KNN: 0.9733333333333334\n",
      "Standard deviation of CV scores for KNN: 0.02494438257849294\n"
     ]
    }
   ],
   "source": [
    "no_of_neighbors=5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=no_of_neighbors)\n",
    "cv_scores_knn = cross_val_score(knn_model, X, y, cv=no_of_neighbors)\n",
    "\n",
    "\n",
    "print(\"Cross-validation scores for KNN:\", cv_scores_knn)\n",
    "print(\"Mean CV score for KNN:\", cv_scores_knn.mean())\n",
    "print(\"Standard deviation of CV scores for KNN:\", cv_scores_knn.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
