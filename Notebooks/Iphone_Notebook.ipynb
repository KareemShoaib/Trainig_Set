{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breast_Cancer_NB_KMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan = pd.read_csv('loan_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Gender Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_gender = LabelEncoder()\n",
    "df_loan['Gender'] = label_encoder_gender.fit_transform(df_loan['Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding all dates , and string containing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_unix_timestamp(date_string):\n",
    "    timestamp = datetime.strptime(date_string, \"%m/%d/%Y\").timestamp()\n",
    "    return int(timestamp)\n",
    "\n",
    "date_columns = [\"effective_date\", \"due_date\"] \n",
    "\n",
    "for col in date_columns:\n",
    "    # Encode using Unix timestamp\n",
    "    df_loan[col + '_UnixTimestamp'] = df_loan[col].apply(encode_unix_timestamp)\n",
    "\n",
    "df_loan.drop(columns=['effective_date'], inplace=True)\n",
    "df_loan.drop(columns=['due_date'], inplace=True) \n",
    "\n",
    "# Encode the target variable 'loan_status' to numerical values\n",
    "label_encoder_loan_status = LabelEncoder()\n",
    "df_loan['loan_status_encoded'] = label_encoder_loan_status.fit_transform(df_loan['loan_status'])\n",
    "df_loan.drop(columns=['loan_status'], inplace=True) \n",
    "\n",
    "# Encode the 'education' column\n",
    "label_encoder_education = LabelEncoder()\n",
    "df_loan['education_encoded'] = label_encoder_education.fit_transform(df_loan['education'])\n",
    "df_loan.drop(columns=['education'], inplace=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the numerical values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "numerical_columns_loan = df_loan.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_loan[numerical_columns_loan] = scaler.fit_transform(df_loan[numerical_columns_loan])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loan = df_loan.drop(columns=['loan_status_encoded'])  # Features\n",
    "y_loan = df_loan['loan_status_encoded']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets with a 70-30 ratio\n",
    "X_train_loan, X_valid_loan, y_train_loan, y_valid_loan = train_test_split(X_loan, y_loan, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_loan = 20\n",
    "batch_size_loan = 32\n",
    "learning_rate_loan = 0.001  # Not applicable for Naive Bayes\n",
    "no_of_neighbors_loan = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data and Printing validation accuracy for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs for Naive Bayes on Loan Dataset\n",
      "Epoch 1/20 - Validation Accuracy: 0.9519\n",
      "Epoch 2/20 - Validation Accuracy: 0.9519\n",
      "Epoch 3/20 - Validation Accuracy: 0.9519\n",
      "Epoch 4/20 - Validation Accuracy: 0.9519\n",
      "Epoch 5/20 - Validation Accuracy: 0.9519\n",
      "Epoch 6/20 - Validation Accuracy: 0.9519\n",
      "Epoch 7/20 - Validation Accuracy: 0.9519\n",
      "Epoch 8/20 - Validation Accuracy: 0.9519\n",
      "Epoch 9/20 - Validation Accuracy: 0.9519\n",
      "Epoch 10/20 - Validation Accuracy: 0.9519\n",
      "Epoch 11/20 - Validation Accuracy: 0.9519\n",
      "Epoch 12/20 - Validation Accuracy: 0.9519\n",
      "Epoch 13/20 - Validation Accuracy: 0.9519\n",
      "Epoch 14/20 - Validation Accuracy: 0.9519\n",
      "Epoch 15/20 - Validation Accuracy: 0.9519\n",
      "Epoch 16/20 - Validation Accuracy: 0.9519\n",
      "Epoch 17/20 - Validation Accuracy: 0.9519\n",
      "Epoch 18/20 - Validation Accuracy: 0.9519\n",
      "Epoch 19/20 - Validation Accuracy: 0.9519\n",
      "Epoch 20/20 - Validation Accuracy: 0.9519\n"
     ]
    }
   ],
   "source": [
    "nb_model_loan = GaussianNB()\n",
    "\n",
    "print(\"Epochs for Naive Bayes on Loan Dataset\")\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "for epoch in range(epochs_loan):\n",
    "    # Shuffle the training data (optional)\n",
    "    shuffled_indices = np.random.permutation(len(X_train_loan))\n",
    "    X_train_shuffled = X_train_loan.iloc[shuffled_indices]\n",
    "    y_train_shuffled = y_train_loan.iloc[shuffled_indices]\n",
    "    \n",
    "    # Mini-batch training (not applicable for Naive Bayes, but keeping the structure consistent)\n",
    "    for batch_start in range(0, len(X_train_loan), batch_size_loan):\n",
    "        batch_end = batch_start + batch_size_loan\n",
    "        X_batch = X_train_shuffled.iloc[batch_start:batch_end]\n",
    "        y_batch = y_train_shuffled[batch_start:batch_end]\n",
    "        \n",
    "        # Fit the model on the current mini-batch\n",
    "        nb_model_loan.partial_fit(X_batch, y_batch, classes=np.unique(y_loan))\n",
    "        \n",
    "    # Evaluate the model on the validation set\n",
    "    y_valid_pred = nb_model_loan.predict(X_valid_loan[X_train_loan.columns])  # Use only the columns present during training\n",
    "    accuracy = accuracy_score(y_valid_loan, y_valid_pred)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{epochs_loan} - Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training Data and Printing validation accuracy for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs for KNN on Loan Dataset\n",
      "Epoch 1/20 - Validation Accuracy: 0.9808\n",
      "Epoch 2/20 - Validation Accuracy: 0.9808\n",
      "Epoch 3/20 - Validation Accuracy: 0.9808\n",
      "Epoch 4/20 - Validation Accuracy: 0.9808\n",
      "Epoch 5/20 - Validation Accuracy: 0.9808\n",
      "Epoch 6/20 - Validation Accuracy: 0.9808\n",
      "Epoch 7/20 - Validation Accuracy: 0.9808\n",
      "Epoch 8/20 - Validation Accuracy: 0.9808\n",
      "Epoch 9/20 - Validation Accuracy: 0.9808\n",
      "Epoch 10/20 - Validation Accuracy: 0.9808\n",
      "Epoch 11/20 - Validation Accuracy: 0.9808\n",
      "Epoch 12/20 - Validation Accuracy: 0.9808\n",
      "Epoch 13/20 - Validation Accuracy: 0.9808\n",
      "Epoch 14/20 - Validation Accuracy: 0.9808\n",
      "Epoch 15/20 - Validation Accuracy: 0.9808\n",
      "Epoch 16/20 - Validation Accuracy: 0.9808\n",
      "Epoch 17/20 - Validation Accuracy: 0.9808\n",
      "Epoch 18/20 - Validation Accuracy: 0.9808\n",
      "Epoch 19/20 - Validation Accuracy: 0.9808\n",
      "Epoch 20/20 - Validation Accuracy: 0.9808\n"
     ]
    }
   ],
   "source": [
    "knn_model_loan = KNeighborsClassifier(n_neighbors=no_of_neighbors_loan)\n",
    "\n",
    "print(\"Epochs for KNN on Loan Dataset\")\n",
    "\n",
    "# Train the KNN model\n",
    "for epoch in range(epochs_loan):\n",
    "    # Shuffle the training data (optional)\n",
    "    shuffled_indices = np.random.permutation(len(X_train_loan))\n",
    "    X_train_shuffled = X_train_loan.iloc[shuffled_indices]\n",
    "    y_train_shuffled = y_train_loan.iloc[shuffled_indices]\n",
    "\n",
    "    # Fit the model on the entire training data\n",
    "    knn_model_loan.fit(X_train_shuffled, y_train_shuffled)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_valid_pred = knn_model_loan.predict(X_valid_loan[X_train_loan.columns])  # Use only the columns present during training\n",
    "    accuracy = accuracy_score(y_valid_loan, y_valid_pred)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{epochs_loan} - Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "CV and Standard deviation of NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for GaussianNB on Loan Dataset:\n",
      "Cross-validation scores: [0.74285714 0.94202899 1.         1.         1.        ]\n",
      "Mean CV score: 0.9369772256728778\n",
      "Standard deviation of CV scores: 0.09962302653651318\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-validation scores for GaussianNB on Loan Dataset:\")\n",
    "cv_scores_nb_loan = cross_val_score(nb_model_loan, X_loan, y_loan, cv=5)  # 5-fold cross-validation\n",
    "print(\"Cross-validation scores:\", cv_scores_nb_loan)\n",
    "print(\"Mean CV score:\", cv_scores_nb_loan.mean())\n",
    "print(\"Standard deviation of CV scores:\", cv_scores_nb_loan.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV and Standard deviation of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for KNN on Loan Dataset:\n",
      "Cross-validation scores: [1.         0.98550725 1.         0.95652174 0.86956522]\n",
      "Mean CV score: 0.9623188405797102\n",
      "Standard deviation of CV scores: 0.04901894065300802\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-validation scores for KNN on Loan Dataset:\")\n",
    "cv_scores_knn_loan = cross_val_score(knn_model_loan, X_loan, y_loan, cv=5)  # 5-fold cross-validation\n",
    "print(\"Cross-validation scores:\", cv_scores_knn_loan)\n",
    "print(\"Mean CV score:\", cv_scores_knn_loan.mean())\n",
    "print(\"Standard deviation of CV scores:\", cv_scores_knn_loan.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
